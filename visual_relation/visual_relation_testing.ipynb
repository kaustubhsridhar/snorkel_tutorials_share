{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Relationship Detection\n",
    "\n",
    "In this tutorial, we focus on the task of classifying visual relationships between objects in an image. For any given image, there might be many such relationships, defined formally as a `subject <predictate> object` (e.g. `person <riding> bike`). As an example, in the relationship `man riding bicycle`), \"man\" and \"bicycle\" are the subject and object, respectively, and \"riding\" is the relationship predicate.\n",
    "\n",
    "![Visual Relationships](https://cs.stanford.edu/people/ranjaykrishna/vrd/dataset.png)\n",
    "\n",
    "In the examples of the relationships shown above, the red box represents the _subject_ while the green box represents the _object_. The _predicate_ (e.g. kick) denotes what relationship connects the subject and the object.\n",
    "\n",
    "For the purpose of this tutorial, we operate over the [Visual Relationship Detection (VRD) dataset](https://cs.stanford.edu/people/ranjaykrishna/vrd/) and focus on action relationships. We define our classification task as **identifying which of three relationships holds between the objects represented by a pair of bounding boxes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM = 0.5\n",
    "N_EPS = 50\n",
    "LR = 0.1\n",
    "DEPS_NAME = 'CDGAM'\n",
    "FLIP = True\n",
    "\n",
    "#PARAM = 1\n",
    "#N_EPS = 50\n",
    "#LR = 0.05\n",
    "#DEPS_NAME = 'Varma'\n",
    "#FLIP = True\n",
    "\n",
    "#PARAM = -1\n",
    "#N_EPS = 50\n",
    "#LR = 0.05\n",
    "#DEPS_NAME = 'Empty' \n",
    "#FLIP = True\n",
    "\n",
    "#PARAM = 0.5\n",
    "#N_EPS = 100\n",
    "#LR = 0.025\n",
    "#DEPS_NAME = 'NM_NP'# New Method \"New\" Policy (where old policy is delta heuristic and new policy is discarding matrix if zero cols/rows)\n",
    "#FLIP = True\n",
    "\n",
    "#PARAM = 0.5\n",
    "#N_EPS = 100\n",
    "#LR = 0.1\n",
    "#DEPS_NAME = 'Varma_Gold' \n",
    "#FLIP = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.basename(os.getcwd()) == \"snorkel-tutorials\":\n",
    "    os.chdir(\"visual_relation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Dataset\n",
    "We load the VRD dataset and filter images with at least one action predicate in it, since these are more difficult to classify than geometric relationships like `above` or `next to`. We load the train, valid, and test sets as Pandas `DataFrame` objects with the following fields:\n",
    "- `label`: The relationship between the objects. 0: `RIDE`, 1: `CARRY`, 2: `OTHER` action predicates\n",
    "- `object_bbox`: coordinates of the bounding box for the object `[ymin, ymax, xmin, xmax]`\n",
    "- `object_category`: category of the object\n",
    "- `source_img`: filename for the corresponding image the relationship is in\n",
    "- `subject_bbox`: coordinates of the bounding box for the object `[ymin, ymax, xmin, xmax]`\n",
    "- `subject_category`: category of the subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running this notebook for the first time, it will take ~15 mins to download all the required sample data.\n",
    "\n",
    "The sampled version of the dataset **uses the same 26 data points across the train, dev, and test sets.\n",
    "This setting is meant to demonstrate quickly how Snorkel works with this task, not to demonstrate performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Relationships:  635\n",
      "Dev Relationships:  194\n",
      "Test Relationships:  216\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_category</th>\n",
       "      <th>object_category</th>\n",
       "      <th>subject_bbox</th>\n",
       "      <th>object_bbox</th>\n",
       "      <th>label</th>\n",
       "      <th>source_img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>umbrella</td>\n",
       "      <td>table</td>\n",
       "      <td>[94, 175, 306, 590]</td>\n",
       "      <td>[336, 489, 324, 458]</td>\n",
       "      <td>2</td>\n",
       "      <td>2113966890_c65030a7e7_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>person</td>\n",
       "      <td>bench</td>\n",
       "      <td>[159, 594, 504, 767]</td>\n",
       "      <td>[200, 479, 109, 846]</td>\n",
       "      <td>2</td>\n",
       "      <td>8054281885_ebbbfa2672_b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>person</td>\n",
       "      <td>table</td>\n",
       "      <td>[152, 540, 342, 648]</td>\n",
       "      <td>[539, 767, 1, 1023]</td>\n",
       "      <td>2</td>\n",
       "      <td>5813297357_f210a455f9_b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>person</td>\n",
       "      <td>train</td>\n",
       "      <td>[275, 346, 440, 489]</td>\n",
       "      <td>[226, 641, 254, 712]</td>\n",
       "      <td>2</td>\n",
       "      <td>3572969356_2b01616f71_b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>person</td>\n",
       "      <td>[226, 641, 254, 712]</td>\n",
       "      <td>[320, 353, 345, 375]</td>\n",
       "      <td>1</td>\n",
       "      <td>3572969356_2b01616f71_b.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_category object_category          subject_bbox  \\\n",
       "0         umbrella           table   [94, 175, 306, 590]   \n",
       "1           person           bench  [159, 594, 504, 767]   \n",
       "2           person           table  [152, 540, 342, 648]   \n",
       "3           person           train  [275, 346, 440, 489]   \n",
       "4            train          person  [226, 641, 254, 712]   \n",
       "\n",
       "            object_bbox  label                   source_img  \n",
       "0  [336, 489, 324, 458]      2  2113966890_c65030a7e7_o.jpg  \n",
       "1  [200, 479, 109, 846]      2  8054281885_ebbbfa2672_b.jpg  \n",
       "2   [539, 767, 1, 1023]      2  5813297357_f210a455f9_b.jpg  \n",
       "3  [226, 641, 254, 712]      2  3572969356_2b01616f71_b.jpg  \n",
       "4  [320, 353, 345, 375]      1  3572969356_2b01616f71_b.jpg  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import load_vrd_data\n",
    "# changed IMAGES_URL in download_full_data.sh to \"http://imagenet.stanford.edu/internal/jcjohns/scene_graphs/sg_dataset.zip\"\n",
    "# setting sample=False will take ~3 hours to run (downloads full VRD dataset)\n",
    "sample = False\n",
    "is_test = os.environ.get(\"TRAVIS\") == \"true\" or os.environ.get(\"IS_TEST\") == \"true\"\n",
    "\n",
    "if FLIP:\n",
    "    df_train, df_test, df_valid = load_vrd_data(sample, is_test)\n",
    "else:\n",
    "    df_train, df_valid, df_test = load_vrd_data(sample, is_test)\n",
    "    \n",
    "print(\"Train Relationships: \", len(df_train))\n",
    "print(\"Dev Relationships: \", len(df_valid))\n",
    "print(\"Test Relationships: \", len(df_test))\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the training `DataFrame` will have a labels field with all -1s. This denotes the lack of labels for that particular dataset. In this tutorial, we will assign probabilistic labels to the training set by writing labeling functions over attributes of the subject and objects!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Writing Labeling Functions\n",
    "We now write labeling functions to detect what relationship exists between pairs of bounding boxes. To do so, we can encode various intuitions into the labeling functions:\n",
    "* _Categorical_ intution: knowledge about the categories of subjects and objects usually involved in these relationships (e.g., `person` is usually the subject for predicates like `ride` and `carry`)\n",
    "* _Spatial_ intuition: knowledge about the relative positions of the subject and objects (e.g., subject is usually higher than the object for the predicate `ride`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RIDE = 0\n",
    "CARRY = 1\n",
    "OTHER = 2\n",
    "ABSTAIN = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with labeling functions that encode categorical intuition: we use knowledge about common subject-object category pairs that are common for `RIDE` and `CARRY` and also knowledge about what subjects or objects are unlikely to be involved in the two relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "# Category-based LFs\n",
    "@labeling_function()\n",
    "def lf_ride_object(x):\n",
    "    if x.subject_category == \"person\":\n",
    "        if x.object_category in [\n",
    "            \"bike\",\n",
    "            \"snowboard\",\n",
    "            \"motorcycle\",\n",
    "            \"horse\",\n",
    "            \"bus\",\n",
    "            \"truck\",\n",
    "            \"elephant\",\n",
    "        ]:\n",
    "            return RIDE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def lf_carry_object(x):\n",
    "    if x.subject_category == \"person\":\n",
    "        if x.object_category in [\"bag\", \"surfboard\", \"skis\"]:\n",
    "            return CARRY\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def lf_carry_subject(x):\n",
    "    if x.object_category == \"person\":\n",
    "        if x.subject_category in [\"chair\", \"bike\", \"snowboard\", \"motorcycle\", \"horse\"]:\n",
    "            return CARRY\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def lf_not_person(x):\n",
    "    if x.subject_category != \"person\":\n",
    "        return OTHER\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now encode our spatial intuition, which includes measuring the distance between the bounding boxes and comparing their relative areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "YMIN = 0\n",
    "YMAX = 1\n",
    "XMIN = 2\n",
    "XMAX = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Distance-based LFs\n",
    "@labeling_function()\n",
    "def lf_ydist(x):\n",
    "    if x.subject_bbox[XMAX] < x.object_bbox[XMAX]:\n",
    "        return OTHER\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def lf_dist(x):\n",
    "    if np.linalg.norm(np.array(x.subject_bbox) - np.array(x.object_bbox)) <= 1000:\n",
    "        return OTHER\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "def area(bbox):\n",
    "    return (bbox[YMAX] - bbox[YMIN]) * (bbox[XMAX] - bbox[XMIN])\n",
    "\n",
    "\n",
    "# Size-based LF\n",
    "@labeling_function()\n",
    "def lf_area(x):\n",
    "    if area(x.subject_bbox) / area(x.object_bbox) <= 0.5:\n",
    "        return OTHER\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the labeling functions have varying empirical accuracies and coverages. Due to class imbalance in our chosen relationships, labeling functions that label the `OTHER` class have higher coverage than labeling functions for `RIDE` or `CARRY`. This reflects the distribution of classes in the dataset as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 635/635 [00:00<00:00, 6063.34it/s]\n",
      "100%|██████████| 194/194 [00:00<00:00, 5648.93it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "lfs = [\n",
    "    lf_ride_object,\n",
    "    lf_carry_object,\n",
    "    lf_carry_subject,\n",
    "    lf_not_person,\n",
    "    lf_ydist,\n",
    "    lf_dist,\n",
    "    lf_area,\n",
    "]\n",
    "\n",
    "applier = PandasLFApplier(lfs)\n",
    "L_train = applier.apply(df_train)\n",
    "L_valid = applier.apply(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lf_ride_object</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.164948</td>\n",
       "      <td>0.164948</td>\n",
       "      <td>0.164948</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_carry_object</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.113402</td>\n",
       "      <td>0.113402</td>\n",
       "      <td>0.113402</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_carry_subject</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_not_person</th>\n",
       "      <td>3</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.252577</td>\n",
       "      <td>0.252577</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>0.816327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_ydist</th>\n",
       "      <td>4</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.175258</td>\n",
       "      <td>86</td>\n",
       "      <td>34</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_dist</th>\n",
       "      <td>5</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.994845</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.298969</td>\n",
       "      <td>123</td>\n",
       "      <td>70</td>\n",
       "      <td>0.637306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_area</th>\n",
       "      <td>6</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.324742</td>\n",
       "      <td>0.324742</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>51</td>\n",
       "      <td>12</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "lf_ride_object    0      [0]  0.164948  0.164948   0.164948       24   \n",
       "lf_carry_object   1      [1]  0.113402  0.113402   0.113402       18   \n",
       "lf_carry_subject  2      [1]  0.020619  0.020619   0.020619        4   \n",
       "lf_not_person     3      [2]  0.252577  0.252577   0.020619       40   \n",
       "lf_ydist          4      [2]  0.618557  0.618557   0.175258       86   \n",
       "lf_dist           5      [2]  0.994845  0.845361   0.298969      123   \n",
       "lf_area           6      [2]  0.324742  0.324742   0.061856       51   \n",
       "\n",
       "                  Incorrect  Emp. Acc.  \n",
       "lf_ride_object            8   0.750000  \n",
       "lf_carry_object           4   0.818182  \n",
       "lf_carry_subject          0   1.000000  \n",
       "lf_not_person             9   0.816327  \n",
       "lf_ydist                 34   0.716667  \n",
       "lf_dist                  70   0.637306  \n",
       "lf_area                  12   0.809524  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "Y_valid = df_valid.label.values\n",
    "LFAnalysis(L_valid, lfs).lf_summary(Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Find dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from Our_Monitors.CD_Monitor import CDM, Informed_LabelModel\n",
    "from Our_Monitors.CDGA_Monitor import CDGAM\n",
    "from Our_Monitors.New_Monitor import NM\n",
    "from Our_Monitors.utils import ModVarma_InCov\n",
    "\n",
    "L_dev = L_valid\n",
    "Y_dev = Y_valid\n",
    "\n",
    "from dependency_model.varma_deps_functions import get_varma_edges, get_varma_with_gold_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (0, 3), (0, 4), (0, 5), (1, 3), (1, 4), (1, 6), (2, 3), (3, 6), (4, 6), (5, 6)]\n"
     ]
    }
   ],
   "source": [
    "def overall_deps_fn(deps_name, param):\n",
    "    if deps_name == 'CDM':\n",
    "        deps = CDM(L_dev, Y_dev, k=3, sig=param, policy = 'new', verbose=False, return_more_info = False)\n",
    "    elif deps_name == 'CDGAM':\n",
    "        deps = CDGAM(L_dev, k=3, sig=param, policy = 'new', verbose = False, return_more_info = False)\n",
    "    elif deps_name == 'NM':\n",
    "        deps = NM(L_dev, Y_dev, k=3, sig=param, policy = 'old', verbose=False, return_more_info = False)\n",
    "    elif deps_name == 'NM_NP':\n",
    "        deps = NM(L_dev, Y_dev, k=3, sig=param, policy = 'new', verbose=False, return_more_info = False)\n",
    "    elif deps_name == 'Mod_Varma':\n",
    "        deps = ModVarma_InCov(L_dev, Y_dev, thresh=param)\n",
    "    elif deps_name == 'Varma':\n",
    "        deps = get_varma_edges(L_dev, thresh=param)\n",
    "    elif deps_name == 'Varma_Gold':\n",
    "        deps = get_varma_with_gold_edges(L_dev, Y_dev, thresh=param)\n",
    "    elif deps_name == 'Empty':\n",
    "        deps = []\n",
    "    return deps\n",
    "\n",
    "deps = overall_deps_fn(DEPS_NAME, PARAM)\n",
    "print(deps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train and evaluate Label Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "from snorkel.classification import DictDataLoader\n",
    "from model import SceneGraphDataset, create_model\n",
    "from snorkel.utils import probs_to_preds # added\n",
    "import torchvision.models as models\n",
    "from snorkel.classification import Trainer\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output2\n",
    "\n",
    "label_model = Informed_LabelModel(edges = deps, cardinality=3, verbose=True)\n",
    "label_model.fit(L_train, seed=12345, lr=LR, log_freq=N_EPS/10, n_epochs=N_EPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [00:00<00:00, 2545.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label model's score on valid set:  0.8170731707317073\n",
      "label model's score on test set:  0.7988505747126436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "L_test = applier.apply(df_test)\n",
    "Y_test = df_test.label.values\n",
    "\n",
    "score = label_model.score(L_dev, Y_dev)['accuracy']\n",
    "score_test = label_model.score(L_test, Y_test)['accuracy']\n",
    "\n",
    "print(\"label model's score on valid set: \", score)\n",
    "print(\"label model's score on test set: \", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up dataloaders for end extraction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate labels\n",
    "df_train[\"labels\"] = probs_to_preds(label_model.predict_proba(L_train))\n",
    "\n",
    "#Changes ./model.py's line 79 to take labels column instead of label column\n",
    "#So, add a column called labels to valid, test dl which is duplicate of label\n",
    "df_valid[\"labels\"] = df_valid[\"label\"]\n",
    "df_test[\"labels\"] = df_test[\"label\"]\n",
    "\n",
    "# Also set up dataloaders\n",
    "if sample:\n",
    "    TRAIN_DIR = \"data/VRD/sg_dataset/samples\"\n",
    "else:\n",
    "    TRAIN_DIR = \"data/VRD/sg_dataset/sg_train_images\"\n",
    "# added test dl\n",
    "TEST_DIR = \"data/VRD/sg_dataset/sg_test_images\"\n",
    "\n",
    "if FLIP:\n",
    "    DIR2 = TEST_DIR\n",
    "    DIR3 = TRAIN_DIR\n",
    "else:\n",
    "    DIR2 = TRAIN_DIR\n",
    "    DIR3 = TEST_DIR\n",
    "\n",
    "dl_train = DictDataLoader(\n",
    "    SceneGraphDataset(\"train_dataset\", \"train\", TRAIN_DIR, df_train),\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    ")\n",
    "dl_valid = DictDataLoader(\n",
    "    SceneGraphDataset(\"valid_dataset\", \"valid\", DIR2, df_valid),\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    ")\n",
    "dl_test = DictDataLoader(\n",
    "    SceneGraphDataset(\"test_dataset\", \"test\", DIR3, df_test),\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train and evaluate end extraction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0::   0%|          | 0/40 [00:00<?, ?it/s]/home/kaustubh-anaconda/snorkel_tutorials_share/visual_relation/model.py:135: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  return self.word_embs.loc[word].as_matrix()\n",
      "Epoch 0:: 100%|██████████| 40/40 [01:28<00:00,  2.22s/it, model/all/train/loss=0.925, model/all/train/lr=0.001, visual_relation_task/valid_dataset/valid/f1_micro=0.665]\n",
      "Epoch 1:: 100%|██████████| 40/40 [01:40<00:00,  2.51s/it, model/all/train/loss=0.521, model/all/train/lr=0.001, visual_relation_task/valid_dataset/valid/f1_micro=0.691]\n",
      "Epoch 2:: 100%|██████████| 40/40 [01:43<00:00,  2.60s/it, model/all/train/loss=0.383, model/all/train/lr=0.001, visual_relation_task/valid_dataset/valid/f1_micro=0.711]\n",
      "Epoch 3:: 100%|██████████| 40/40 [01:04<00:00,  1.62s/it, model/all/train/loss=0.368, model/all/train/lr=0.001, visual_relation_task/valid_dataset/valid/f1_micro=0.691]\n"
     ]
    }
   ],
   "source": [
    "# CLF VALIDATION!\n",
    "n_clf_epochs = 4 # from validation analysis notebook\n",
    "\n",
    "# define clf architecture\n",
    "# initialize pretrained feature extractor\n",
    "cnn = models.resnet18(pretrained=True)\n",
    "model = create_model(cnn)\n",
    "\n",
    "# train clf\n",
    "trainer = Trainer(\n",
    "    n_epochs=n_clf_epochs,  # increase for improved performance\n",
    "    lr=1e-3,\n",
    "    checkpointing=True,\n",
    "    checkpointer_config={\"checkpoint_dir\": \"checkpoint\"},\n",
    ")\n",
    "trainer.fit(model, [dl_train, dl_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6898148148148148\n",
      "[[  4  12  33]\n",
      " [  0  23  14]\n",
      " [  0   8 122]]\n"
     ]
    }
   ],
   "source": [
    "# evaluate clf additions\n",
    "results = model.predict(dl_test, return_preds = True)\n",
    "gold = results['golds']['visual_relation_task']\n",
    "preds = results['preds']['visual_relation_task']\n",
    "print(accuracy_score(gold, preds))\n",
    "#print(precision_recall_fscore_support(gold, preds, average='micro'))\n",
    "print(confusion_matrix(gold, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
